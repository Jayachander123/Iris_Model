{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "588a14e0",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" style=\"background-color:#006a79; color:white; padding:0px 10px; border-radius:5px;\"><h2 style='margin:10px 5px'>Iris Data classification</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4014b9f8",
   "metadata": {},
   "source": [
    "## Table of contents \n",
    "1. Importing Libraries\n",
    "2. Load Data\n",
    "3. Understand the Data\n",
    "4. Data Visualization\n",
    "5. Train-Validation Split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682168f1",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" style=\"background-color:#006a79; color:white; padding:0px 10px; border-radius:5px;\"><h2 \n",
    "style='margin:10px 5px'>1. Importing Libraries</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5fb63d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pandas.plotting import scatter_matrix\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold, cross_val_score \n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb303976",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" style=\"background-color:#006a79; color:white; padding:0px 10px; border-radius:5px;\"><h2 style='margin:10px 5px'>2. Load Data</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a78f8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data():\n",
    "    \n",
    "    ''' Reading .csv file of iris data, this function also supports if there is no data available. \n",
    "    This function will download dataset.'''\n",
    "    \n",
    "    try:\n",
    "        df = pd.read_csv('data/iris.csv')\n",
    "        df = df[['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm', 'Species']]\n",
    "    except Exception as e:\n",
    "        try:\n",
    "            data_url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\"\n",
    "            column_url = \"https://archive.ics.uci.edu/ml/datasets/iris\"\n",
    "\n",
    "            r = requests.get(data_url)\n",
    "            if not os.path.exists('data/'):\n",
    "               # Create a new directory because it does not exist\n",
    "               os.makedirs('data/')\n",
    "            else:\n",
    "                pass\n",
    "            with open(\"data/iris.csv\", 'wb') as f:\n",
    "                f.write(r.content)\n",
    "\n",
    "            colnames = ['SepalLengthCm','SepalWidthCm', 'PetalLengthCm','PetalWidthCm', 'Species']\n",
    "            df = pd.read_csv('data/iris.csv', names=colnames)\n",
    "            df.to_csv('data/iris.csv')\n",
    "        except Exception as e:\n",
    "            print('Error in downloading the Dataset:', e)\n",
    "            raise\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdbb0a75",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" style=\"background-color:#006a79; color:white; padding:0px 10px; border-radius:5px;\"><h2 style='margin:10px 5px'>3. Understanding Data </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a7cfde",
   "metadata": {},
   "source": [
    "The Iris Data has 150 instances and 5 attributes with 4 Independent(Sepal length, Sepal Width, Petal length and Petal width) and one Dependent Variable (Species).\n",
    "\n",
    "The numerical values of all 4 independent variables have the same scale (centimeters) and similar ranges between 0 and 8 centimeters. There are three duplicate observations so after removing the duplicates dataset size decreased to 147 instances. There are no null values found. Replacing a few Outliers with median instead of removing them as sample size if very small.\n",
    "\n",
    "The Dependent Variable has three unique values with each has 50 instances, After removing duplicates, we have one class not more than 4% of other class. so usually depends on dataset when one class is 30% to 60% greater than other is considered class imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68e44db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_shape(df):\n",
    "    \n",
    "    ''' return shape of dataset'''\n",
    "    \n",
    "    print(df.shape)\n",
    "    return df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5dac2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def duplicate_drop(df):\n",
    "    \n",
    "    ''' if there are duplicate records this function will drop them'''\n",
    "    \n",
    "    try:       \n",
    "        df_duplicate = df[df.duplicated()]\n",
    "        if len(df_duplicate)>0:\n",
    "            df = df.drop_duplicates().reset_index(drop=True)\n",
    "        else:\n",
    "            pass\n",
    "    except Exception as e:\n",
    "        print('Error when addressing Duplicates: ', e)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca516416",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outlier(rw):\n",
    "    \n",
    "    ''' values above 75 percentile + 1.5*InterQuartileRange(IQR) \n",
    "     or lower than 25 percentile - 1.5*InterQuartileRange(IQR) are outliers'''\n",
    "    \n",
    "    try:        \n",
    "        upper = rw.quantile(0.75)\n",
    "        lower = rw.quantile(0.25)\n",
    "        iqr = upper - lower\n",
    "        factor=iqr*1.5\n",
    "        cond = (rw>=upper+factor) | (rw<=lower-factor)\n",
    "        rw.loc[cond] = rw.median()\n",
    "    except Exception as e:\n",
    "        print('Error when addressing Outliers: ', e)\n",
    "    return rw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4522ed34",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" style=\"background-color:#006a79; color:white; padding:0px 10px; border-radius:5px;\"><h2 style='margin:10px 5px'>4. Data Visualization </h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c64701",
   "metadata": {},
   "source": [
    "It looks like perhaps two of the input variables have a Gaussian distribution. Pandas, Matploitlib and Seaborn as the libraries used for each plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "45bef3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_visualization(df):   \n",
    "    ''' return a few visualization plot to better understand the data''' \n",
    "    try:      \n",
    "        print('Plotting BOX PLOT')\n",
    "        df.plot(kind='box', subplots=True, layout=(2,3), sharex=False, sharey=False)\n",
    "        plt.show()\n",
    "        \n",
    "        print('Plotting HISTOGRAM')\n",
    "        df.hist()\n",
    "        plt.show()\n",
    "        \n",
    "        print('Plotting HEATMAP to see Correlations')\n",
    "        plt.figure(figsize=(12,10)) \n",
    "        p=sns.heatmap(df.corr(), annot=True,cmap ='RdYlGn')\n",
    "        \n",
    "        print('Plotting Scatter Plot for data variations') \n",
    "        sns.pairplot(df, hue='Species', markers='*')\n",
    "    except Exception as e:\n",
    "        print('Error in plotting Visualizations: ', e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d6879a",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" style=\"background-color:#006a79; color:white; padding:0px 10px; border-radius:5px;\"><h2 style='margin:10px 5px'>5. Train-Validation Split </h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b8bae9",
   "metadata": {},
   "source": [
    "Splitting the loaded dataset into two, 80% of which we will use to train our models and 20% that we will hold back as a validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a74c6e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Data_split(df):  \n",
    "    '''split the dataset into train and test sets''' \n",
    "    try:\n",
    "        array = df.values\n",
    "        X = array[:,0:4]\n",
    "        Y = array[:,4]\n",
    "        validation_size = 0.20\n",
    "        seed = 7\n",
    "        X_train, X_validation, Y_train, Y_validation = train_test_split(X, Y, test_size=validation_size, random_state=seed)\n",
    "    except Exception as e:\n",
    "        print('Error in creating training and validation sets :', e)\n",
    "        raise\n",
    "    return X_train, X_validation, Y_train, Y_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae27c567",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
